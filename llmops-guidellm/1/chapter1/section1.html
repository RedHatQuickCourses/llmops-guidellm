<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Introduction to Performance Benchmarking :: Model Performance Benchmarking with GuideLLM</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Model Performance Benchmarking with GuideLLM</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-guidellm" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Model Performance Benchmarking with GuideLLM</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Platform</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="mission.html">Mission One</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Model Performance Benchmarking with GuideLLM</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section2.html">Running Your First Benchmark</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section3.html">Interpreting Benchmark Results</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section4.html">Advanced Benchmarking Scenarios</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section5.html">From Benchmarks to Business Insights</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section6.html">Course Wrap-up</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Model Performance Benchmarking with GuideLLM</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Model Performance Benchmarking with GuideLLM</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Model Performance Benchmarking with GuideLLM</a></li>
    <li><a href="section1.html">Introduction to Performance Benchmarking</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Introduction to Performance Benchmarking</h1>
<div class="sect1">
<h2 id="_why_performance_evaluation_matters"><a class="anchor" href="#_why_performance_evaluation_matters"></a>Why Performance Evaluation Matters</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In Generative AI systems, evaluating system performance including latency, throughput, and resource utilization is just as important as evaluating model accuracy or quality. Here&#8217;s why:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>User Experience</strong>: High latency leads to sluggish interactions, which is unacceptable in chatbots, copilots, and real-time applications. Users expect sub-second responses.</p>
</li>
<li>
<p><strong>Scalability</strong>: Throughput determines how many requests a system can handle in parallel. For enterprise GenAI apps, high throughput is essential to serve multiple users or integrate with high-frequency backend processes.</p>
</li>
<li>
<p><strong>Cost Efficiency</strong>: Slow or inefficient systems require more compute to serve the same volume of requests. Optimizing performance directly reduces cloud GPU costs and improves ROI.</p>
</li>
<li>
<p><strong>Fair Benchmarking</strong>: A model may appear “better” in isolated evaluation, but if it requires excessive inference time or hardware, it may not be viable in production. True model evaluation must balance quality and performance.</p>
</li>
<li>
<p><strong>Deployment Readiness</strong>: Latency and throughput impact architectural decisions (e.g., batching, caching, distributed serving). Measuring them ensures a model is viable under real-world constraints.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_is_guidellm"><a class="anchor" href="#_what_is_guidellm"></a>What is GuideLLM?</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>GuideLLM</strong> is a toolkit for evaluating and optimizing the deployment of LLMs. By simulating real-world inference workloads, GuideLLM enables you to easily assess the performance, resource requirements, and cost implications of deploying LLMs on various hardware configurations. This approach ensures efficient, scalable, and cost-effective LLM inference serving while maintaining high service quality.</p>
</div>
<div class="paragraph">
<p>GuideLLM is now officially a part of the vLLM upstream project. This toolset is one of the primary ways Red Hat internal teams are benchmarking customer models and will be the main framework we will recommend to our customers.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><mark>#</mark> <strong>Trusty AI vs GuideLLM</strong></p>
</div>
<div class="paragraph">
<p>It&#8217;s important to distinguish GuideLLM from Trusty AI. Trusty AI&#8217;s scope is responsible AI (explainability, fairness, bias detection), while GuideLLM is focused purely on system performance benchmarking and optimization.</p>
</div>
<div class="paragraph">
<p>That being said, there are some current crossovers. Trusty AI incorporates lm-eval-harness and GuideLLM is roadmapped to include this test harness as well. Trusty AI will continue to be an incorporated and supported operator deployment in RHOAI. There are currently no plans to have a similar deployment method for GuideLLM.</p>
</div>
</div>
</div>
<hr>
<div class="paragraph">
<p>For our lab today, we will utilize the tekton pipeline on our OpenShift AI cluster. A pipeline deployment provides the following benefits:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Automation and reproducibility</p>
</li>
<li>
<p>Cloud-native / kubernetes-native</p>
</li>
<li>
<p>Scalability and resource optimization</p>
</li>
<li>
<p>Modular</p>
</li>
<li>
<p>Integration with existing MLOps workflows</p>
</li>
<li>
<p>Version control / auditability</p>
</li>
<li>
<p>Better handling of complex, multi-stage workflows</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Scalability and resource optimization: benchmarking can be resource intensive particularly when simulating high loads or testing large models. The dynamic provisioning/de-provisioning of necessary resources with tekton can handle this well for the expensive compute.
</td>
</tr>
</table>
</div>
<hr>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
