<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Introduction to Performance Benchmarking :: Model Performance Benchmarking with GuideLLM</title>
    <link rel="prev" href="index.html">
    <link rel="next" href="section2.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Model Performance Benchmarking with GuideLLM</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-guidellm" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Model Performance Benchmarking with GuideLLM</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="#intro.adoc">intro.adoc</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="mission.html">Your Place in the Adventure</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Evaluating System Performance with GuideLLM</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="3">
    <a class="nav-link" href="section1.html">Introduction to Performance Benchmarking</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="section2.html">Running Your First Benchmark</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="section3.html">Interpreting Benchmark Results</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="section4.html">Advanced Benchmarking Scenarios</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="section5.html">Course Wrap-up</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Model Performance Benchmarking with GuideLLM</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Model Performance Benchmarking with GuideLLM</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Model Performance Benchmarking with GuideLLM</a></li>
    <li><a href="#intro.adoc">intro.adoc</a></li>
    <li><a href="index.html">Evaluating System Performance with GuideLLM</a></li>
    <li><a href="section1.html">Introduction to Performance Benchmarking</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Introduction to Performance Benchmarking</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Welcome to the Model Performance Benchmarking with GuideLLM course. In this course, you will learn how to quantitatively measure, analyze, and optimize the performance of Large Language Models deployed on Red Hat OpenShift AI.</p>
</div>
<div class="paragraph">
<p>By the end of this course, you will be able to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Set up an automated benchmarking pipeline using GuideLLM and Tekton.</p>
</li>
<li>
<p>Execute various performance tests that simulate real-world workloads.</p>
</li>
<li>
<p>Interpret key performance metrics like latency, throughput, and token generation speed.</p>
</li>
<li>
<p>Connect performance results to business outcomes, such as user experience and infrastructure cost.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_why_performance_evaluation_matters"><a class="anchor" href="#_why_performance_evaluation_matters"></a>Why Performance Evaluation Matters</h3>
<div class="paragraph">
<p>In Generative AI systems, evaluating system performance including latency, throughput, and resource utilization is just as important as evaluating model accuracy or quality. Here&#8217;s why:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>User Experience</strong>: High latency leads to sluggish interactions, which is unacceptable in chatbots, copilots, and real-time applications. Users expect sub-second responses.</p>
</li>
<li>
<p><strong>Scalability</strong>: Throughput determines how many requests a system can handle in parallel. For enterprise GenAI apps, high throughput is essential to serve multiple users or integrate with high-frequency backend processes.</p>
</li>
<li>
<p><strong>Cost Efficiency</strong>: Slow or inefficient systems require more compute to serve the same volume of requests. Optimizing performance directly reduces cloud GPU costs and improves ROI.</p>
</li>
<li>
<p><strong>Fair Benchmarking</strong>: A model may appear “better” in isolated evaluation, but if it requires excessive inference time or hardware, it may not be viable in production. True model evaluation must balance quality and performance.</p>
</li>
<li>
<p><strong>Deployment Readiness</strong>: Latency and throughput impact architectural decisions (e.g., batching, caching, distributed serving). Measuring them ensures a model is viable under real-world constraints.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_what_is_guidellm"><a class="anchor" href="#_what_is_guidellm"></a>What is GuideLLM?</h3>
<div class="paragraph">
<p><strong>GuideLLM</strong> is a toolkit for evaluating and optimizing the deployment of LLMs. By simulating real-world inference workloads, GuideLLM enables you to easily assess the performance, resource requirements, and cost implications of deploying LLMs on various hardware configurations. This approach ensures efficient, scalable, and cost-effective LLM inference serving while maintaining high service quality.</p>
</div>
<div class="paragraph">
<p>GuideLLM is now officially a part of the vLLM upstream project. This toolset is one of the primary ways Red Hat internal teams are benchmarking customer models and will be the main framework we will recommend to our customers.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It&#8217;s important to distinguish GuideLLM from Trusty AI. Trusty AI&#8217;s scope is responsible AI (explainability, fairness, bias detection), while GuideLLM is focused purely on system performance benchmarking and optimization.
</td>
</tr>
</table>
</div>
</div>
<div class="sect1">
<h2 id="_module_1_setting_up_your_benchmarking_environment"><a class="anchor" href="#_module_1_setting_up_your_benchmarking_environment"></a>Module 1: Setting Up Your Benchmarking Environment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this module, we will set up an automated Tekton pipeline on OpenShift AI to run our GuideLLM benchmarks. Using a Tekton pipeline provides automation, reproducibility, and efficient resource management for our tests.</p>
</div>
<div class="sect2">
<h3 id="_1_1_install_the_tekton_cli"><a class="anchor" href="#_1_1_install_the_tekton_cli"></a>1.1 Install the Tekton CLI</h3>
<div class="paragraph">
<p>First, ensure the Tekton CLI (<code>tkn</code>) is installed in your terminal. This tool will allow us to interact with our pipelines.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">curl -sL $(curl -s https://api.github.com/repos/tektoncd/cli/releases/latest | grep "browser_download_url.*_Linux_x86_64.tar.gz" | cut -d '"' -f 4) | sudo tar -xz -C /usr/local/bin tkn
tkn version</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_1_2_deploy_the_guidellm_pipeline_resources"><a class="anchor" href="#_1_2_deploy_the_guidellm_pipeline_resources"></a>1.2 Deploy the GuideLLM Pipeline Resources</h3>
<div class="paragraph">
<p>Next, we will clone the necessary Git repositories and apply the Kubernetes resources that define our pipeline, its tasks, and the required storage.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Clone the ETX vLLM optimization repo which contains the pipeline definition.</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">git clone https://github.com/redhat-ai-services/etx-llm-optimization-and-inference-leveraging.git
cd etx-llm-optimization-and-inference-leveraging</code></pre>
</div>
</div>
</li>
<li>
<p>Clone the GuideLLM pipeline repo itself.</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">git clone https://github.com/jhurlocker/guidellm-pipeline.git</code></pre>
</div>
</div>
</li>
<li>
<p>Apply the PVC, task, pipeline, and Minio bucket configuration to your cluster. Ensure you are in the correct namespace (<code>vllm</code>).</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">oc apply -f guidellm-pipeline/pipeline/upload-results-task.yaml -n vllm
oc apply -f guidellm-pipeline/pipeline/guidellm-pipeline.yaml -n vllm
oc apply -f guidellm-pipeline/pipeline/pvc.yaml -n vllm
oc apply -f guidellm-pipeline/pipeline/guidellm-benchmark-task.yaml -n vllm
oc apply -f guidellm-pipeline/pipeline/mino-bucket.yaml -n vllm</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>With these resources created, we are now ready to execute a benchmark.</p>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="index.html">Evaluating System Performance with GuideLLM</a></span>
  <span class="next"><a href="section2.html">Running Your First Benchmark</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
